<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="x-ua-compatible" content="ie=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta
      name="description"
      content="Chain-of-Thought Hijacking: A jailbreak attack on reasoning models that achieves state-of-the-art success rates"
    />

    <title>Chain-of-Thought Hijacking</title>

    <!-- Stylesheets -->
    <link
      rel="stylesheet"
      href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css"
    />
    <link
      rel="stylesheet"
      href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css"
    />
    <link rel="stylesheet" href="css/app.css" />

    <!-- Scripts -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
    <script src="js/app.js"></script>
  </head>

  <body>
    <div class="container" id="main">
      <!-- Title -->
      <header class="row">
        <h2 class="col-md-12 text-center">
          <b>
            <font size="+6">Chain-of-Thought Hijacking</font>
            <img
              src="assets/Jailbreak_Icon_Color.png"
              alt="🔓"
              style="
                width: 5rem;
                height: 5rem;
                display: inline-block;
                vertical-align: middle;
                margin-left: 10px;
              "
            />
          </b>
        </h2>
      </header>

      <!-- Authors -->
      <section class="row" style="margin-bottom: 0.5em">
        <div class="col-md-12 text-center">
          <!-- First row authors -->
          <ul class="list-inline">
            <li>
              <a
                href="https://jianli-zhao.github.io/"
                target="_blank"
                style="color: inherit"
                >Jianli Zhao<sup>1</sup></a
              >
            </li>
            <li>
              <a
                href="https://tingchenfu.github.io/"
                target="_blank"
                style="color: inherit"
                >Tingchen Fu<sup>2</sup></a
              >
            </li>
            <li>
              <a
                href="http://rylanschaeffer.github.io/"
                target="_blank"
                style="color: inherit"
                >Rylan Schaeffer<sup>4</sup></a
              >
            </li>
            <li>
              <a
                href="https://www.mrinanksharma.net"
                target="_blank"
                style="color: inherit"
                >Mrinank Sharma<sup>6</sup></a
              >
            </li>
            <li>
              <a
                href="https://fbarez.github.io/"
                target="_blank"
                style="color: inherit"
                >Fazl Barez<sup>3,5,7</sup></a
              >
            </li>
          </ul>
        </div>
      </section>

      <!-- Affiliations -->
      <section class="row" style="margin-bottom: 1.5em">
        <div class="col-md-12 text-center">
          <p
            style="
              font-size: 14px;
              color: rgb(132, 132, 132);
              line-height: 1.6;
              margin-bottom: 0;
            "
          >
            <sup>1</sup>Independent &nbsp;&nbsp; <sup>2</sup>Renmin University
            of China &nbsp;&nbsp; <sup>3</sup>University of Oxford &nbsp;&nbsp;
            <sup>4</sup>Stanford University
          </p>
          <p
            style="
              font-size: 14px;
              color: rgb(132, 132, 132);
              line-height: 1.6;
              margin-top: 3px;
            "
          >
            <sup>5</sup>WhiteBox &nbsp;&nbsp; <sup>6</sup>Anthropic &nbsp;&nbsp;
            <sup>7</sup>Martian
          </p>
        </div>
      </section>

      <!-- Links -->
      <section class="row">
        <div class="col-md-8 col-md-offset-2 text-center">
          <h3>
            <a href="assets/Hijacking_paper.pdf" target="_blank">Paper</a>
            &nbsp;&nbsp;|&nbsp;&nbsp;
            <a href="https://github.com/jianli-zhao/Hijacking" target="_blank"
              >Code</a
            >
            &nbsp;&nbsp;|&nbsp;&nbsp;
            <a
              href="#examples"
              onclick="document.getElementById('examples-section').scrollIntoView({behavior: 'smooth'});"
              >Example</a
            >
          </h3>
        </div>
      </section>

      <!-- Abstract -->
      <section class="row">
        <div class="col-md-8 col-md-offset-2">
          <h3>Abstract</h3>
          <p class="text-justify">
            Large reasoning models (LRMs) achieve higher task performance by
            allocating more inference-time compute, and prior works suggest this
            scaled reasoning may also strengthen safety by improving refusal.
            Yet we find the opposite: the same reasoning can be used to bypass
            safety. We introduce <em>Chain-of-Thought Hijacking</em>, a
            jailbreak attack on reasoning models. The attack pads harmful
            requests with long sequences of harmless reasoning. Across
            HarmBench, CoT Hijacking reaches a
            <strong>99%, 94%, 100%, and 94%</strong> attack success rate (ASR)
            on Gemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet,
            respectively—far exceeding prior jailbreak methods for LRMs. To
            understand the effectiveness of our attack, we turn to a mechanistic
            analysis, which shows that mid layers encode the
            <em>strength of safety checking</em>, while late layers encode the
            <em>verification outcome</em>. Long benign CoT dilutes both signals
            by shifting attention away from harmful tokens. Targeted ablations
            of attention heads identified by this analysis causally decrease
            refusal, confirming their role in a safety subnetwork. These results
            show that the most interpretable form of reasoning—explicit CoT—can
            itself become a jailbreak vector when combined with final-answer
            cues. We release prompts, outputs, and judge decisions to facilitate
            replication.
          </p>
        </div>
      </section>

      <!-- Attack Pipeline Figure -->
      <section class="col-md-12 text-center" style="margin-top: 20px">
        <img
          src="assets/Jailbreaking_Models_Fig03_v2.png"
          style="width: 55%; height: auto"
          class="img-responsive"
          alt="Attack Pipeline"
        />
      </section>

      <!-- Figure Caption -->
      <section
        class="col-md-8 col-md-offset-2"
        style="color: rgb(83, 83, 83); margin-top: 10px"
      >
        <p>
          <strong>Figure 1: Jailbreak Method Pipeline.</strong> The upper part
          illustrates the process of generating our jailbreak query, while the
          lower part shows how the target model is attacked.
        </p>
      </section>

      <!-- Spacing -->
      <section class="col-md-12" style="margin-top: 1px"></section>

      <!-- Experimental Results Chart -->
      <section class="row">
        <div class="col-md-8 col-md-offset-2">
          <div class="chart-container">
            <canvas id="resultsChart"></canvas>
          </div>
          <p
            class="text-center"
            style="margin-top: 20px; color: rgb(83, 83, 83)"
          >
            <strong>Figure 2: Attack Success Rate Comparison.</strong> We
            evaluated CoT Hijacking on 100 HarmBench samples across four
            frontier reasoning models, comparing against state-of-the-art
            baseline jailbreak methods. Our method achieves significantly higher
            attack success rates across all models.
          </p>
        </div>
      </section>

      <!-- Spacing -->
      <section class="col-md-12" style="margin-top: 30px"></section>

      <!-- Example Jailbreaks -->
      <section id="examples-section" class="row">
        <div class="col-md-8 col-md-offset-2">
          <h3 class="text-center" style="margin-bottom: 20px">
            Example Jailbreak
          </h3>
          <p class="text-center" style="color: red; margin-bottom: 20px">
            WARNING: EXAMPLE CONTAIN HARMFUL CONTENT
          </p>
          <div class="text-center">
            <img
              src="assets/Jailbreaking_Models_Fig02_v2.png"
              style="width: 100%; height: auto"
              class="img-responsive"
              alt="Example Jailbreaks"
            />
          </div>
          <p
            class="text-center"
            style="margin-top: 15px; color: rgb(83, 83, 83)"
          >
            <strong>Figure 3: Safe vs. Jailbreak Example.</strong> Grey
            highlights indicate puzzle content, red highlights mark malicious
            requests/contents.
          </p>
        </div>
      </section>

      <!-- Spacing -->
      <section class="col-md-12" style="margin-top: 30px"></section>

      <!-- Citation -->
      <section class="row">
        <div class="col-md-8 col-md-offset-2">
          <h3>Citation</h3>
          <div class="form-group col-md-10 col-md-offset-1">
            <textarea id="bibtex" class="form-control" readonly>
@article{To be arxived
  ...
  ...
  ...
  ...
}</textarea
            >
          </div>
        </div>
      </section>

      <!-- Footer -->
      <footer class="row">
        <div class="col-md-8 col-md-offset-2">
          <p class="text-justify" style="margin-top: 30px">
            <strong>⚠️ Safety Notice:</strong> This research is for
            <strong>defensive security purposes only</strong>. Do not use these
            methods for malicious purposes. We release this work to help the
            community build more robust safety mechanisms.
          </p>
          <p class="text-justify">
            This site's design is adapted from
            <a
              href="https://jplhughes.github.io/bon-jailbreaking/"
              target="_blank"
              >Best-of-N Jailbreaking</a
            >.
          </p>
        </div>
      </footer>
    </div>

    <!-- Initialize Chart -->
    <script>
      $(document).ready(function () {
        // Initialize Chart.js
        const canvas = document.getElementById("resultsChart");
        if (canvas && typeof Chart !== "undefined") {
          const ctx = canvas.getContext("2d");
          const data = {
            labels: [
              "Gemini 2.5 Pro",
              "GPT-o4 Mini",
              "Grok 3 Mini",
              "Claude 4 Sonnet",
            ],
            datasets: [
              {
                label: "Mousetrap",
                data: [44, 25, 60, 22],
                backgroundColor: "rgba(226, 232, 240, 0.7)",
                borderColor: "rgba(148, 163, 184, 1)",
                borderWidth: 1,
              },
              {
                label: "H-CoT",
                data: [60, 65, 66, 11],
                backgroundColor: "rgba(203, 213, 225, 0.7)",
                borderColor: "rgba(100, 116, 139, 1)",
                borderWidth: 1,
              },
              {
                label: "AutoRAN",
                data: [69, 47, 61, 5],
                backgroundColor: "rgba(148, 163, 184, 0.7)",
                borderColor: "rgba(71, 85, 105, 1)",
                borderWidth: 1,
              },
              {
                label: "CoT Hijacking (Ours)",
                data: [99, 94, 100, 94],
                backgroundColor: "rgba(59, 130, 246, 0.8)",
                borderColor: "rgba(37, 99, 235, 1)",
                borderWidth: 2,
              },
            ],
          };

          const config = {
            type: "bar",
            data: data,
            options: {
              responsive: true,
              maintainAspectRatio: true,
              plugins: {
                legend: {
                  position: "top",
                  labels: {
                    font: {
                      size: 13,
                      family: "'Lato', Verdana, Helvetica, sans-serif",
                    },
                    padding: 15,
                    usePointStyle: true,
                  },
                },
                title: {
                  display: true,
                  text: "Attack Success Rate (%) Comparison",
                  font: {
                    size: 18,
                    weight: "bold",
                    family: "'Lato', Verdana, Helvetica, sans-serif",
                  },
                  padding: 20,
                },
                tooltip: {
                  backgroundColor: "rgba(0, 0, 0, 0.8)",
                  padding: 12,
                  titleFont: {
                    size: 14,
                  },
                  bodyFont: {
                    size: 13,
                  },
                  callbacks: {
                    label: function (context) {
                      return (
                        context.dataset.label + ": " + context.parsed.y + "%"
                      );
                    },
                  },
                },
              },
              scales: {
                y: {
                  beginAtZero: true,
                  max: 105,
                  ticks: {
                    callback: function (value) {
                      return value + "%";
                    },
                    font: {
                      size: 12,
                    },
                  },
                  grid: {
                    color: "rgba(0, 0, 0, 0.05)",
                  },
                },
                x: {
                  ticks: {
                    font: {
                      size: 12,
                    },
                  },
                  grid: {
                    display: false,
                  },
                },
              },
              interaction: {
                mode: "index",
                intersect: false,
              },
            },
          };

          new Chart(ctx, config);
        }
      });
    </script>
  </body>
</html>
